{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94c856e-6148-4edf-87b6-8819cad507b3",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3b6ecd-b407-4775-b646-8a1f185e6753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "import json\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import defaultdict\n",
    "from utils import load_json, load_pkl\n",
    "courses = load_json('data/courses_processed.txt')[0]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e59f326-7f33-4d4d-b08f-5eaf56350f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from previous notebook computing TF-IDF matrix X \n",
    "\n",
    "# Extract the unique terms in course descriptions and names\n",
    "unique_terms = list(set((' '.join([course['description'] for course in courses])).split(' ')))\n",
    "course_names = [course['name'] for course in courses]\n",
    "\n",
    "# Step 1: Tokenize and build vocabulary\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "vocab = set()\n",
    "doc_tokens = []\n",
    "for course in courses:\n",
    "    doc = course['description']\n",
    "    tokens = tokenize(doc)\n",
    "    doc_tokens.append(tokens)\n",
    "    vocab.update(tokens)\n",
    "vocab = sorted(vocab)  # consistent order\n",
    "vocab_index = {term: i for i, term in enumerate(vocab)}\n",
    "\n",
    "# Step 2: Compute term frequency (TF)\n",
    "def compute_tf(tokens):\n",
    "    tf = defaultdict(float)\n",
    "    for word in tokens:\n",
    "        tf[word] += 1\n",
    "    total = len(tokens)\n",
    "    for word in tf:\n",
    "        tf[word] /= total\n",
    "    return tf\n",
    "tfs = [compute_tf(tokens) for tokens in doc_tokens]\n",
    "\n",
    "# Step 3: Compute inverse document frequency (IDF)\n",
    "def compute_idf(doc_tokens, vocab):\n",
    "    N = len(course_names)\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        df = sum(1 for tokens in doc_tokens if word in tokens)\n",
    "        idf[word] = math.log((1 + N) / (1 + df)) + 1  # smoothed\n",
    "    return idf\n",
    "idf = compute_idf(doc_tokens, vocab)\n",
    "\n",
    "# Step 4: Compute TF-IDF vectors for each document\n",
    "def compute_tfidf(tf, idf, vocab_index):\n",
    "    vec = np.zeros(len(vocab_index))\n",
    "    for word, val in tf.items():\n",
    "        if word in idf:\n",
    "            vec[vocab_index[word]] = val * idf[word]\n",
    "    return vec\n",
    "doc_vectors = [compute_tfidf(tf, idf, vocab_index) for tf in tfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51495f3a-8247-4984-a14e-afdd25fd4c7f",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30996571-88c3-4710-b35c-73e542b1ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data matrix and compute SVD \n",
    "matrix = np.vstack(doc_vectors)\n",
    "matrix_sparse = csr_matrix(matrix.T, dtype=float)\n",
    "U, S, Vt = svds(matrix_sparse, k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bfda972-7606-41d1-926f-50d02c080152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10122, 854)\n",
      "(10122, 300)\n",
      "(300, 854)\n"
     ]
    }
   ],
   "source": [
    "#Verify correct dimentionality \n",
    "print(matrix_sparse.shape)\n",
    "print(U.shape)\n",
    "print(Vt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ff6c1-ff82-4b75-b59b-df734209dcba",
   "metadata": {},
   "source": [
    "- U is a (10122 X 300) term-topic matrix. Each column of U represents the contribution of all the 10122 terms on a main topic/concept.\n",
    "- Vt is a (300 X 854) document-topic matrix. Each row of Vt represents the contribution of all the 854 document on a main topic/concept.  \n",
    "- Finally, S is a (300 X 300) diagonal matrix containing on it's main diagonal the weights of the top 300 topics/concepts in increasing order.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863a87aa-3fce-420c-ae98-7f51285930b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 singular values of X are: \n",
      "  [3.93625354 3.52946105 2.92617437 2.42848641 1.63712864 1.60160462\n",
      " 1.45895513 1.42724407 1.38418801 1.35372694 1.32973585 1.27306686\n",
      " 1.24551032 1.2341388  1.19652518 1.16029898 1.14360026 1.14243644\n",
      " 1.12273007 1.11779834]\n"
     ]
    }
   ],
   "source": [
    "print(\"The top 20 singular values of X are: \\n \", np.sort(S)[-20:][::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c8c0e-609d-4d3e-bbaa-b508aaaaafe1",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extarction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9ac6491-d692-4b00-b76b-e78391bb592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversing the matrices column or rows to have the eigenvectors in decreasing order\n",
    "U = U[:,::-1]\n",
    "S = S[::-1]\n",
    "Vt = Vt[::-1, :]\n",
    "S = np.diag(S)\n",
    "\n",
    "# useful dictionaries for later functions\n",
    "index_to_term = {i: term for term, i in vocab_index.items()}\n",
    "name_index = {name: i for i, name in enumerate(course_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f7c3d91-4cdb-48da-9992-aad1861d9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the most relevant topics based on a list of terms and course names\n",
    "# params: numbrer_top_terms: number of most relevant terms to display\n",
    "#         number_top_courses: number of most reÃ©evant courses to display\n",
    "#         number_topics: number of concepts/topic to calculate in such way\n",
    "def find_topics(number_top_terms,number_top_courses, number_topics):\n",
    "\n",
    "    for topic_idx in range(number_topics):\n",
    "        print(f\"\\nðŸ”¹ Topic #{topic_idx + 1}\")\n",
    "\n",
    "        # Top terms for this topic\n",
    "        top_term_indices = U[:,topic_idx].argsort()[::-1][:number_top_terms]\n",
    "        top_terms = [index_to_term[i] for i in top_term_indices]\n",
    "        print(\"  Top terms:\", \", \".join(top_terms))\n",
    "\n",
    "        # Top courses for this topic\n",
    "        top_course_indices = Vt[topic_idx,:].argsort()[::-1][:number_top_courses]\n",
    "        top_courses = [course_names[i] for i in top_course_indices]\n",
    "        print(\"  Top courses:\", \", \".join(top_courses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b9f09ac-538e-4616-9e33-63b33b457772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Topic #1\n",
      "  Top terms: 136, 118, 18h00, 172, 083, 164, mage, reserach, agt, 77\n",
      "  Top courses: UE U : Cartography, Studio BA4 (De Vylder & Taillieu), ThÃ©orie et critique du projet MA1 (Gugger), ThÃ©orie et critique du projet MA2 (Geers), ThÃ©orie et critique du projet MA1 (Geers), Principles and Practicals in X-Ray Scattering, Limestone-Calcined Clay - Cement : Characterisation methods, GÃ¶del and recursivity, Satellite communications  systems and networks, Studio MA2 (Escher et GuneWardena)\n",
      "\n",
      "ðŸ”¹ Topic #2\n",
      "  Top terms: rotat, train, month, doctor, propos, candidaci, project, report, student, laboratori\n",
      "  Top courses: Training Rotation (EDNE), Training Rotation (EDMS), Industrial electronics II, Practical - Cole Lab, Optical waves propagation, How people learn II, Biophysics II, Statistical thermodynamics, Integrated circuits technology, Nano CMOS Devices & Technologies for Tera-Bit Circuits and Systems\n",
      "\n",
      "ðŸ”¹ Topic #3\n",
      "  Top terms: project, student, method, model, system, ic, the, learn, laboratori, semest\n",
      "  Top courses: Project 2 (EDIC), Project 1 (EDIC), Optional project in Systems engineering, Project in biomedical technologies, Modelling, optimisation, design and analysis of integrated energy systems, Project in information technologies, Optics III, Atomistic and quantum simulations of materials, Methods of Modelling and Simulation of Materials Science, Power electronics\n",
      "\n",
      "ðŸ”¹ Topic #4\n",
      "  Top terms: model, method, system, optic, process, energi, theori, basic, the, learn\n",
      "  Top courses: Nonlinear Spectroscopy, Medicinal chemistry, Methods of Modelling and Simulation of Materials Science, Laser microprocessing, Optics III, Magnetic confinement, Fundamentals of solid-state materials, Nonlinear Optics, High energy and space astrophysics (UNIGe), Power electronics\n",
      "\n",
      "ðŸ”¹ Topic #5\n",
      "  Top terms: optic, laser, fiber, electron, spectroscopi, waveguid, imag, properti, microscopi, light\n",
      "  Top courses: Optical fibers and fiber devices, Nonlinear Spectroscopy, Nonlinear Optics, Light sources: optical fiber and waveguide lasers, Selected topics in advanced optics, Integrated optics, Optics III, Photomechanics for Engineers, Laser microprocessing, Photonic systems and technology\n",
      "\n",
      "ðŸ”¹ Topic #6\n",
      "  Top terms: fondament, drug, compound, chemic, question, provid, the, biolog, cell, protein\n",
      "  Top courses: Medicinal chemistry, Basic principles of drug action at the cardiovascular system, Current Topics in Chemical Biology 2, Basic principles of drug action at the nervous system, Current Topics in Chemical Biology 1, Chemical biology - tools and methods, Pharmacology and pharmacokinetics, Biological chemistry III, Chemical biology, Practical - Cole Lab\n",
      "\n",
      "ðŸ”¹ Topic #7\n",
      "  Top terms: cell, biolog, protein, microscopi, doctor, edm, tem, research, note, student\n",
      "  Top courses: Stem cell biology and technology, Practical - De Palma Lab, Practical - Suter Lab, Gene transfer and recombinant protein expression in animal cells, Practical - Radtke Lab, Practical - Blokesch Lab, Scanning and Analytical Transmission Electron Microscopy, Practical - GÃ¶nczy Lab, Transmission electron microscopy and diffraction (b), Transmission electron microscopy and diffraction (a)\n",
      "\n",
      "ðŸ”¹ Topic #8\n",
      "  Top terms: energi, convers, magnet, power, plasma, heat, reactor, thermodynam, storag, electron\n",
      "  Top courses: Energy storage in power systems: technologies, applications and future needs, Magnetic confinement, Energy systems engineering, Thermodynamics of energy conversion and storage, Energy conversion and renewable energy, High energy and space astrophysics (UNIGe), Thermal power cycles and heat pump systems, Plasma physics III, Modelling, optimisation, design and analysis of integrated energy systems, Power electronics\n",
      "\n",
      "ðŸ”¹ Topic #9\n",
      "  Top terms: optic, laser, fiber, waveguid, cell, process, system, student, energi, design\n",
      "  Top courses: Optical fibers and fiber devices, Light sources: optical fiber and waveguide lasers, Laser microprocessing, Lasers: theory and modern applications, Nonlinear Optics, Photonic systems and technology, Lasers and applications in chemistry, Integrated optics, Selected topics in advanced optics, Optics III\n",
      "\n",
      "ðŸ”¹ Topic #10\n",
      "  Top terms: tem, research, imag, project, electron, design, fondament, sem, microscop, plan\n",
      "  Top courses: Transmission electron microscopy and diffraction (b), Transmission electron microscopy and diffraction (a), Scanning electron microscopy techniques (a), Scanning electron microscopy techniques (b), Scanning and Analytical Transmission Electron Microscopy, Medicinal chemistry, Electron microscopy: advanced methods, Project in Biotechnology, Studio MA2 (Escher et GuneWardena), 3D Electron Microscopy and FIB-Nanotomography\n"
     ]
    }
   ],
   "source": [
    "find_topics(10,10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6987cebe-c720-48ff-96ad-58a2f789ab06",
   "metadata": {},
   "source": [
    "We Can label these 10 dominant concepts/ topics in the following way:\n",
    "- Topic #1 => Thesis Projects \n",
    "- Topic #2 => Physics/ Thermodynamics\n",
    "- Topic #3 => Semester Projects \n",
    "- Topic #4 => Modelling\n",
    "- Topic #5 => Advanced Optics and Spectromatry \n",
    "- Topic #6 => Chemistry and Pharmacology \n",
    "- Topic #7 => Biology and Genetics\n",
    "- Topic #8 => Energy\n",
    "- Topic #9 => Optics and Lasers \n",
    "- Topic #10 => Electrical Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1fc25-a962-41d7-a9f6-dc0c032c71a9",
   "metadata": {},
   "source": [
    "Analysis: The resulted groups are somewhat distinctive although we can see that they are infinging on each other a bit. I think that this may be an inherent property of LSI which don't specifically learn anything about the terms and documents themselves and purely relies on the SVD propreties. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d207c-2443-4e97-b6a0-d470a4cd45ad",
   "metadata": {},
   "source": [
    "## 4.6 Document similarity search in concept space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe2e0e79-d32b-42c3-9534-d799d8a63a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate cosine similarity between a term and a document \n",
    "#params: term: word representing a term (string) \n",
    "#        doc: name of a document (string)\n",
    "# returns the similarity score of the given pair. \n",
    "def sim_on_term(term, doc):\n",
    "\n",
    "    u_term = U[vocab_index[term], :]  \n",
    "    v_doc = Vt[:, name_index[doc]]    \n",
    "    \n",
    "    norm_term = np.linalg.norm(u_term)\n",
    "    norm_doc = np.linalg.norm(S @ v_doc)\n",
    "\n",
    "    if norm_term == 0 or norm_doc == 0: return 0.0  \n",
    "\n",
    "    num = u_term @ S @ v_doc\n",
    "    return num / (norm_term * norm_doc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d44379b-6b13-4ad7-862e-04c9f2984462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calclates the docs with the highest similarity score as a given object (term or course name) and prints the top 5 candidates\n",
    "# param: obj: term or course name in string format\n",
    "#        func: function to be used to calculate similarity (depends if obj in a terme or a course name)\n",
    "def find_top5(obj,func):\n",
    "    cos_sim = []\n",
    "    for name in course_names:\n",
    "         if name == obj: continue #skips identical queries (in doc to doc search)   \n",
    "         cos_sim.append((name, func(obj,name)))\n",
    "    sorted_sim = sorted(cos_sim, key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"Top 5 picks for\",obj,\"are:\")\n",
    "    for i in sorted_sim:\n",
    "        print(i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38758a91-d5f5-41fd-824d-e810ed2684df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 picks for facebook are:\n",
      "('Computational Social Media', 0.9233690816098991)\n",
      "('Social media', 0.605095933131071)\n",
      "('How people learn I', 0.4609564152810865)\n",
      "('Internet analytics', 0.33860641253672763)\n",
      "('How people learn II', 0.3272361897318959)\n",
      "\n",
      "\n",
      "Top 5 picks for markov are:\n",
      "('Applied stochastic processes', 0.704051730318847)\n",
      "('Statistical Sequence Processing', 0.6986519338554791)\n",
      "('Applied probability & stochastic processes', 0.6696221156252392)\n",
      "('Markov chains and algorithmic applications', 0.49327318933699016)\n",
      "('Fundamentals in statistical pattern recognition', 0.2789491251742943)\n",
      "\n",
      "\n",
      "Top 5 picks for chain are:\n",
      "('Supply chain management', 0.8232309923660509)\n",
      "('Mathematical models in supply chain management', 0.7213647148259263)\n",
      "('Operations: economics & strategy', 0.5662845045186415)\n",
      "('Applied stochastic processes', 0.5321343134932818)\n",
      "('Applied probability & stochastic processes', 0.4680315320741975)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_top5(\"facebook\",sim_on_term)\n",
    "find_top5(\"markov\",sim_on_term)\n",
    "find_top5(\"chain\",sim_on_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87ae51-2175-4e12-8585-d3daed5fdd80",
   "metadata": {},
   "source": [
    "The results are very satisfactory. \n",
    "- For \"facebook\" we see a list of courses with a great emphasis on people, media and communication which are all related to facebook. \n",
    "- As for \"markov\", being a russian mathematician who mostly contributed to the probabilistic/stochastic field, we see a list of courses that all are encompassing these concepts in one way or another. \n",
    "\n",
    "I belive that this function has brought up better results for the \"facebook\" query and similar results for the \"markov\" query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765269ef-b9af-46a1-ac50-753806362d34",
   "metadata": {},
   "source": [
    "## 4.7 Document-document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ced8da-3332-4216-9d29-3fe47bc0aba7",
   "metadata": {},
   "source": [
    "Given two documets **$d$** and **$d'$**, the cosine similarity is defined as:\n",
    "\n",
    "$$\n",
    "\\text{sim}(d, d') = \\frac{\\mathbf{v_{d}} S \\mathbf{v_{d'}^\\top}}{\\|\\mathbf{v_{d}}\\| \\cdot \\|S\\mathbf{{v_{d'}}}\\|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **$v_d$** and **$v_{d'}$** are the row vectors of the matrix **V** corresponding to the documents $d$ and $d'$ respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "231d01b7-1c28-4160-bfec-73f4919137f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the similarity score between two course names (in string) \n",
    "#params: d1: course name 1\n",
    "#        d2: course name 2\n",
    "#returns: similarity score\n",
    "def sim_on_doc(d1,d2):\n",
    "    v1 = Vt[:,name_index[d1]]\n",
    "    v2 = Vt[:,name_index[d2]]\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(S @v2)\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0: return 0.0\n",
    "    \n",
    "    num = v1 @ S @ v2\n",
    "    return num / (norm1* norm2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb8aac0f-2e85-47ad-b3f5-1c06240c321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 picks for Internet analytics are:\n",
      "('Distributed information systems', 0.5023913425770477)\n",
      "('Computational Social Media', 0.45363016779227094)\n",
      "('A Network Tour of Data Science', 0.43093999637197666)\n",
      "('Applied data analysis', 0.42888051671984206)\n",
      "('Networks out of control', 0.3274893817901586)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_top5(\"Internet analytics\",sim_on_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5d93e-467f-4bf9-83b0-404e27a57c60",
   "metadata": {},
   "source": [
    "The top 5 course picks are quite satisfactory. We see that all of the chosen courses are focused around networks, infortion systems, data analysis which are the core concepts of the \"Internet analytics\" class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
